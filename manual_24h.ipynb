{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320837f7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18e18bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:48.856404Z",
     "start_time": "2024-11-23T16:07:47.904941Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from utils import Dataset, variance_thresholding, standardize, mcc, calculate_metrics, calculate_metrics_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84c8514",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:48.858792Z",
     "start_time": "2024-11-23T16:07:48.857188Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters for Welch's method for estimating power spectrum\n",
    "\n",
    "NPERSEG = 24                    # length of segment\n",
    "NOVERLAP = int(0.75 * NPERSEG)  # overlap of segments\n",
    "NFFT = NPERSEG                  # length of FFT\n",
    "WINDOW = \"hann\"                 # window function type\n",
    "\n",
    "# parameters for saving data\n",
    "PROCESSED_DATA_DIR = \"processed_data24h\"\n",
    "DEPRESJON_PREFIX = \"manual_depresjon24h\"\n",
    "PSYKOSE_PREFIX = \"manual_psykose24h\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef0d95",
   "metadata": {},
   "source": [
    "# Manual feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9515d10",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "657c3d7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:48.864779Z",
     "start_time": "2024-11-23T16:07:48.859367Z"
    }
   },
   "outputs": [],
   "source": [
    "def basic_data_cleaning(data: List[pd.DataFrame]) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Assumes DataFrames with \"timestamp\", \"date\" and \"activity\" columns.\n",
    "    \n",
    "    Performs cleaning operations:\n",
    "    - assure format YYYY-MM-DD HH:MM:SS for \"timestamp\"\n",
    "    - drop redundant \"date\" column\n",
    "    - assure float32 format for \"activity\"\n",
    "    \n",
    "    :param data: list of DataFrames\n",
    "    :returns: list of cleaned DataFrames\n",
    "    \"\"\"\n",
    "    data = [df.copy() for df in data]  # create copy to avoid side effects\n",
    "    \n",
    "    for df in data:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],\n",
    "                                         format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        df.drop(\"date\", axis=1, inplace=True)\n",
    "        df[\"activity\"] = df[\"activity\"].astype(np.float32)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_day_part(df: pd.DataFrame, part: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For given DataFrame with \"timestamp\" column returns only those rows that\n",
    "    correspond to the chosen part of day.\n",
    "    \n",
    "    Parts are \"day\" and \"night\", defined as:\n",
    "    - \"day\": [8:00, 21:00)\n",
    "    - \"night\": [21:00, 8:00)\n",
    "    \n",
    "    :param df: DataFrame to select rows from\n",
    "    :param part: part of day, either \"day\" or \"night\"\n",
    "    :returns: DataFrame, subset of rows of df\n",
    "    \"\"\"\n",
    "    if part == \"day\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 8) &\n",
    "                    (df[\"timestamp\"].dt.hour < 21)]\n",
    "    elif part == \"night\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 21) |\n",
    "                    (df[\"timestamp\"].dt.hour < 8)]\n",
    "    else:\n",
    "        raise ValueError(f'Part should be \"day\" or \"night\", got \"{part}\"')\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_missing_activity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Makes sure that \"timestamp\" column has minute resolution with no missing\n",
    "    values from start to end and replaces all NaNs in \"activity\" column with\n",
    "    mean average value.\n",
    "    \n",
    "    :param data: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    :returns: cleaned DataFrame\n",
    "    \"\"\"\n",
    "    df = df.copy()  # create copy to avoid side effects\n",
    "    \n",
    "    # resample to the basic frequency, i.e. minute; this will create NaNs for\n",
    "    # any rows that may be missing\n",
    "    df = df.resample(\"min\", on=\"timestamp\").mean()\n",
    "    \n",
    "    # recreate index and \"timestamp\" column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # fill any NaNs with mean activity value\n",
    "    df[\"activity\"] = df[\"activity\"].fillna(df[\"activity\"].mean())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def resample(df: pd.DataFrame, freq: str = \"H\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resamples time series DataFrame with given frequency, aggregating each\n",
    "    segment with a mean.\n",
    "\n",
    "    :param df: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    :param freq: resampling frequency passed to Pandas resample() function\n",
    "    :returns: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    \"\"\"\n",
    "    df = df.copy()  # create copy to avoid side effects\n",
    "    \n",
    "    # group with given frequency\n",
    "    df = df.resample(freq, on=\"timestamp\").mean()\n",
    "\n",
    "    # recreate \"timestamp\" column\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def proportion_of_zeros(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates proportion of zeros in given array, i.e. number of zeros divided\n",
    "    by length of array.\n",
    "    \n",
    "    :param x: 1D Numpy array\n",
    "    :returns: proportion of zeros\n",
    "    \"\"\"\n",
    "    # we may be dealing with floating numbers, we can't use direct comparison\n",
    "    zeros_count = np.sum(np.isclose(x, 0))\n",
    "    return zeros_count / len(x)\n",
    "\n",
    "\n",
    "def power_spectral_density(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates power spectral density (PSD) from \"activity\" column of a\n",
    "    DataFrame.\n",
    "    \n",
    "    :param df: DataFrame with \"activity\" column\n",
    "    :returns: 1D Numpy array with power spectral density\n",
    "    \"\"\"\n",
    "    psd = scipy.signal.welch(\n",
    "        x=df[\"activity\"].values,\n",
    "        fs=(1/24),\n",
    "        nperseg=11,\n",
    "        noverlap=10,\n",
    "        nfft=NFFT,\n",
    "        window=WINDOW,\n",
    "        scaling=\"density\"\n",
    "    )[1]\n",
    "    return psd\n",
    "\n",
    "\n",
    "def spectral_flatness(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculates spectral flatness of a signal, i.e. a geometric mean of the\n",
    "    power spectrum divided by the arithmetic mean of the power spectrum.\n",
    "    \n",
    "    If some frequency bins in the power spectrum are close to zero, they are\n",
    "    removed prior to calculation of spectral flatness to avoid calculation of\n",
    "    log(0).\n",
    "    \n",
    "    :param df: DataFrame with \"activity\" column\n",
    "    :returns: spectral flatness value\n",
    "    \"\"\"\n",
    "    power_spectrum = scipy.signal.welch(\n",
    "        df[\"activity\"].values,\n",
    "        fs=(1/24),\n",
    "        nperseg=11,\n",
    "        noverlap=10,\n",
    "        nfft=NFFT,\n",
    "        window=WINDOW,\n",
    "        scaling=\"spectrum\"\n",
    "    )[1]\n",
    "    \n",
    "    non_zeros_mask = ~np.isclose(power_spectrum, 0)\n",
    "    power_spectrum = power_spectrum[non_zeros_mask]\n",
    "    \n",
    "    return scipy.stats.gmean(power_spectrum) / power_spectrum.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c465a53",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16826d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:48.868344Z",
     "start_time": "2024-11-23T16:07:48.865878Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts features from activity signal in time domain.\n",
    "    \n",
    "    :param df_resampled: DataFrame with \"activity\" column\n",
    "    :returns: DataFrame with a single row representing features\n",
    "    \"\"\"\n",
    "    X = df[\"activity\"].values\n",
    "    \n",
    "    features = {\n",
    "        \"minimum\": np.min(X),\n",
    "        \"maximum\": np.max(X),\n",
    "        \"mean\": np.mean(X),\n",
    "        \"median\": np.median(X),\n",
    "        \"variance\": np.var(X, ddof=1),  # apply Bessel's correction\n",
    "        \"kurtosis\": sp.stats.kurtosis(X),\n",
    "        \"skewness\": sp.stats.skew(X),\n",
    "        \"coeff_of_var\": sp.stats.variation(X),\n",
    "        \"iqr\": sp.stats.iqr(X),\n",
    "        \"trimmed_mean\": sp.stats.trim_mean(X, proportiontocut=0.1),\n",
    "        \"entropy\": sp.stats.entropy(X, base=2),\n",
    "        \"proportion_of_zeros\": proportion_of_zeros(X)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9589aaf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:48.871024Z",
     "start_time": "2024-11-23T16:07:48.868916Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_frequency_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts features from activity signal in frequency domain, i.e. calculated\n",
    "    from its Power Spectral Density (PSD).\n",
    "    \n",
    "    :param df: DataFrame with \"activity\" column\n",
    "    :returns: DataFrame with a single row representing features\n",
    "    \"\"\"\n",
    "    X = power_spectral_density(df)\n",
    "    \n",
    "    features = {\n",
    "        \"minimum\": np.min(X),\n",
    "        \"maximum\": np.max(X),\n",
    "        \"mean\": np.mean(X),\n",
    "        \"median\": np.median(X),\n",
    "        \"variance\": np.var(X),\n",
    "        \"kurtosis\": sp.stats.kurtosis(X),\n",
    "        \"skewness\": sp.stats.skew(X),\n",
    "        \"coeff_of_var\": sp.stats.variation(X),\n",
    "        \"iqr\": sp.stats.iqr(X),\n",
    "        \"trimmed_mean\": sp.stats.trim_mean(X, proportiontocut=0.1),\n",
    "        \"entropy\": sp.stats.entropy(X, base=2),\n",
    "        \"spectral_flatness\": spectral_flatness(df)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9867a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:48.874036Z",
     "start_time": "2024-11-23T16:07:48.871489Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_for_dataframes(dfs: List[pd.DataFrame], freq: str = \"H\") \\\n",
    "        -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculates time and frequency features for given DataFrames. Uses given\n",
    "    frequency for resampling.\n",
    "    \n",
    "    Calculates features separately for:\n",
    "    - full 24hs\n",
    "    - days: [8:00, 21:00)\n",
    "    - nights: [21:00, 8:00)\n",
    "    \n",
    "    :param dfs: list of DataFrames to extract features from; each one has to\n",
    "    have \"timestamp\" and \"activity\" columns\n",
    "    :param freq: resampling frequency\n",
    "    :returns: dictionary with keys \"full_24h\", \"day\" and \"night\", corresponding\n",
    "    to features from given parts of day\n",
    "    \"\"\"\n",
    "    full_dfs = basic_data_cleaning(dfs)\n",
    "    full_dfs = [fill_missing_activity(df) for df in full_dfs]\n",
    "    full_dfs = [resample(df, freq=freq) for df in full_dfs]\n",
    "    \n",
    "    night_dfs = [get_day_part(df, part=\"night\") for df in full_dfs]\n",
    "    day_dfs = [get_day_part(df, part=\"day\") for df in full_dfs]\n",
    "\n",
    "    datasets = {}\n",
    "    \n",
    "    for part, list_of_dfs in [(\"full_24h\", full_dfs), (\"night\", night_dfs),\n",
    "                              (\"day\", day_dfs)]:\n",
    "        features = []\n",
    "        for df in list_of_dfs:\n",
    "            time_features = extract_time_features(df)\n",
    "            freq_features = extract_frequency_features(df)\n",
    "\n",
    "            merged_features = pd.merge(\n",
    "                time_features,\n",
    "                freq_features,\n",
    "                left_index=True,\n",
    "                right_index=True,\n",
    "                suffixes=[\"_time\", \"_freq\"]\n",
    "            )\n",
    "            features.append(merged_features)\n",
    "\n",
    "        datasets[part] = pd.concat(features)\n",
    "        datasets[part].reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6d128",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Depresjon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "278e4de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:49.812138Z",
     "start_time": "2024-11-23T16:07:48.874586Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(dirpath=os.path.join(\"data_24h\", \"depresjon\"))\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0234b1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:49.819890Z",
     "start_time": "2024-11-23T16:07:49.812838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-05-07 12:00:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-05-07 12:01:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-05-07 12:02:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-05-07 12:03:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-05-07 12:04:00</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2003-05-08 11:55:00</td>\n",
       "      <td>2003-05-08</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2003-05-08 11:56:00</td>\n",
       "      <td>2003-05-08</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2003-05-08 11:57:00</td>\n",
       "      <td>2003-05-08</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2003-05-08 11:58:00</td>\n",
       "      <td>2003-05-08</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2003-05-08 11:59:00</td>\n",
       "      <td>2003-05-08</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp        date  activity\n",
       "0     2003-05-07 12:00:00  2003-05-07         0\n",
       "1     2003-05-07 12:01:00  2003-05-07       143\n",
       "2     2003-05-07 12:02:00  2003-05-07         0\n",
       "3     2003-05-07 12:03:00  2003-05-07        20\n",
       "4     2003-05-07 12:04:00  2003-05-07       166\n",
       "...                   ...         ...       ...\n",
       "1435  2003-05-08 11:55:00  2003-05-08       259\n",
       "1436  2003-05-08 11:56:00  2003-05-08       190\n",
       "1437  2003-05-08 11:57:00  2003-05-08       306\n",
       "1438  2003-05-08 11:58:00  2003-05-08        91\n",
       "1439  2003-05-08 11:59:00  2003-05-08       296\n",
       "\n",
       "[1440 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb28b3e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:57.295725Z",
     "start_time": "2024-11-23T16:07:49.820608Z"
    }
   },
   "outputs": [],
   "source": [
    "condition_parts_dfs = extract_features_for_dataframes(condition, freq=\"H\")\n",
    "control_parts_dfs = extract_features_for_dataframes(control, freq=\"H\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\"]:\n",
    "    condition_df = condition_parts_dfs[part]\n",
    "    control_df = control_parts_dfs[part]\n",
    "    \n",
    "    entire_df = pd.concat([condition_df, control_df], ignore_index=True)\n",
    "    \n",
    "    # Przypisujemy wynik do słownika datasets\n",
    "    datasets[part] = entire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbfbb10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:57.311445Z",
     "start_time": "2024-11-23T16:07:57.297722Z"
    }
   },
   "outputs": [],
   "source": [
    "for part, df in datasets.items():\n",
    "    filename = f\"{DEPRESJON_PREFIX}_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9c20b2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:57.315356Z",
     "start_time": "2024-11-23T16:07:57.312033Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.concatenate((np.ones(len(condition)), np.zeros(len(control))))\n",
    "y = pd.Series(y, dtype=int)\n",
    "\n",
    "filepath = os.path.join(PROCESSED_DATA_DIR, f\"depresjon_y.csv\")\n",
    "y.to_csv(filepath, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9127c366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:57.325175Z",
     "start_time": "2024-11-23T16:07:57.316009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minimum_time</th>\n",
       "      <th>maximum_time</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>variance_time</th>\n",
       "      <th>kurtosis_time</th>\n",
       "      <th>skewness_time</th>\n",
       "      <th>coeff_of_var_time</th>\n",
       "      <th>iqr_time</th>\n",
       "      <th>trimmed_mean_time</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_freq</th>\n",
       "      <th>median_freq</th>\n",
       "      <th>variance_freq</th>\n",
       "      <th>kurtosis_freq</th>\n",
       "      <th>skewness_freq</th>\n",
       "      <th>coeff_of_var_freq</th>\n",
       "      <th>iqr_freq</th>\n",
       "      <th>trimmed_mean_freq</th>\n",
       "      <th>entropy_freq</th>\n",
       "      <th>spectral_flatness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>395.649994</td>\n",
       "      <td>131.482635</td>\n",
       "      <td>105.699997</td>\n",
       "      <td>16655.847656</td>\n",
       "      <td>-0.920654</td>\n",
       "      <td>0.638463</td>\n",
       "      <td>0.960889</td>\n",
       "      <td>212.062506</td>\n",
       "      <td>120.149170</td>\n",
       "      <td>...</td>\n",
       "      <td>145556.015625</td>\n",
       "      <td>94128.164062</td>\n",
       "      <td>1.245808e+10</td>\n",
       "      <td>0.335413</td>\n",
       "      <td>1.309549</td>\n",
       "      <td>0.766824</td>\n",
       "      <td>68011.867188</td>\n",
       "      <td>131411.703125</td>\n",
       "      <td>3.339275</td>\n",
       "      <td>0.781018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.083333</td>\n",
       "      <td>432.483337</td>\n",
       "      <td>153.253464</td>\n",
       "      <td>97.983337</td>\n",
       "      <td>20828.339844</td>\n",
       "      <td>-1.155962</td>\n",
       "      <td>0.531038</td>\n",
       "      <td>0.921882</td>\n",
       "      <td>247.795844</td>\n",
       "      <td>142.218353</td>\n",
       "      <td>...</td>\n",
       "      <td>225564.921875</td>\n",
       "      <td>66185.421875</td>\n",
       "      <td>7.144961e+10</td>\n",
       "      <td>-0.185189</td>\n",
       "      <td>1.162469</td>\n",
       "      <td>1.185027</td>\n",
       "      <td>291117.929688</td>\n",
       "      <td>191007.359375</td>\n",
       "      <td>2.800678</td>\n",
       "      <td>0.442222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>339.666656</td>\n",
       "      <td>124.177773</td>\n",
       "      <td>99.625000</td>\n",
       "      <td>12966.193359</td>\n",
       "      <td>-1.028185</td>\n",
       "      <td>0.526891</td>\n",
       "      <td>0.897678</td>\n",
       "      <td>184.895827</td>\n",
       "      <td>115.246666</td>\n",
       "      <td>...</td>\n",
       "      <td>337368.875000</td>\n",
       "      <td>233032.718750</td>\n",
       "      <td>9.313090e+10</td>\n",
       "      <td>-0.446068</td>\n",
       "      <td>0.971081</td>\n",
       "      <td>0.904569</td>\n",
       "      <td>379323.562500</td>\n",
       "      <td>306780.781250</td>\n",
       "      <td>3.145580</td>\n",
       "      <td>0.615705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>447.583344</td>\n",
       "      <td>128.460403</td>\n",
       "      <td>101.724998</td>\n",
       "      <td>14834.280273</td>\n",
       "      <td>0.110828</td>\n",
       "      <td>0.837585</td>\n",
       "      <td>0.928159</td>\n",
       "      <td>193.966663</td>\n",
       "      <td>114.235825</td>\n",
       "      <td>...</td>\n",
       "      <td>293284.031250</td>\n",
       "      <td>243482.046875</td>\n",
       "      <td>2.841528e+10</td>\n",
       "      <td>-1.273162</td>\n",
       "      <td>0.381854</td>\n",
       "      <td>0.574761</td>\n",
       "      <td>266578.562500</td>\n",
       "      <td>286987.468750</td>\n",
       "      <td>3.457804</td>\n",
       "      <td>0.826515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>368.250000</td>\n",
       "      <td>102.386108</td>\n",
       "      <td>59.950001</td>\n",
       "      <td>11585.225586</td>\n",
       "      <td>0.219186</td>\n",
       "      <td>1.074547</td>\n",
       "      <td>1.029128</td>\n",
       "      <td>136.641668</td>\n",
       "      <td>88.289169</td>\n",
       "      <td>...</td>\n",
       "      <td>75315.054688</td>\n",
       "      <td>50414.445312</td>\n",
       "      <td>2.197785e+09</td>\n",
       "      <td>0.339903</td>\n",
       "      <td>1.245119</td>\n",
       "      <td>0.622459</td>\n",
       "      <td>29237.988281</td>\n",
       "      <td>69791.164062</td>\n",
       "      <td>3.455590</td>\n",
       "      <td>0.847506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037604</td>\n",
       "      <td>19.043478</td>\n",
       "      <td>4.587317</td>\n",
       "      <td>4.795832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.289002</td>\n",
       "      <td>2.780218</td>\n",
       "      <td>5.765709e-01</td>\n",
       "      <td>0.321710</td>\n",
       "      <td>-1.308182</td>\n",
       "      <td>0.331727</td>\n",
       "      <td>0.825352</td>\n",
       "      <td>2.412409</td>\n",
       "      <td>3.599787</td>\n",
       "      <td>0.904552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040242</td>\n",
       "      <td>8.400519</td>\n",
       "      <td>3.171385</td>\n",
       "      <td>3.366502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236217</td>\n",
       "      <td>0.231677</td>\n",
       "      <td>5.128690e-03</td>\n",
       "      <td>0.249235</td>\n",
       "      <td>-0.071112</td>\n",
       "      <td>0.303174</td>\n",
       "      <td>0.016871</td>\n",
       "      <td>0.235667</td>\n",
       "      <td>3.629814</td>\n",
       "      <td>0.945994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>19.043478</td>\n",
       "      <td>4.587318</td>\n",
       "      <td>4.795832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>1.543398e-08</td>\n",
       "      <td>-0.032443</td>\n",
       "      <td>0.335318</td>\n",
       "      <td>0.304669</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>3.632658</td>\n",
       "      <td>0.951204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.416664</td>\n",
       "      <td>3.309028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262.791931</td>\n",
       "      <td>19.043477</td>\n",
       "      <td>4.587317</td>\n",
       "      <td>4.795832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8990.534180</td>\n",
       "      <td>10806.850586</td>\n",
       "      <td>8.876594e+06</td>\n",
       "      <td>0.656679</td>\n",
       "      <td>-1.430759</td>\n",
       "      <td>0.331389</td>\n",
       "      <td>2489.757812</td>\n",
       "      <td>9508.233398</td>\n",
       "      <td>3.597398</td>\n",
       "      <td>0.898052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.009722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>19.043473</td>\n",
       "      <td>4.587317</td>\n",
       "      <td>4.795831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113264</td>\n",
       "      <td>0.136604</td>\n",
       "      <td>1.324863e-03</td>\n",
       "      <td>0.377519</td>\n",
       "      <td>-1.322600</td>\n",
       "      <td>0.321361</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>3.606872</td>\n",
       "      <td>0.912811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      minimum_time  maximum_time   mean_time  median_time  variance_time  \\\n",
       "0         0.966667    395.649994  131.482635   105.699997   16655.847656   \n",
       "1         2.083333    432.483337  153.253464    97.983337   20828.339844   \n",
       "2         0.583333    339.666656  124.177773    99.625000   12966.193359   \n",
       "3         0.916667    447.583344  128.460403   101.724998   14834.280273   \n",
       "4         2.666667    368.250000  102.386108    59.950001   11585.225586   \n",
       "...            ...           ...         ...          ...            ...   \n",
       "1046      0.000000      0.950000    0.039583     0.000000       0.037604   \n",
       "1049      0.000000      0.816667    0.058333     0.000000       0.040242   \n",
       "1050      0.000000      0.033333    0.001389     0.000000       0.000046   \n",
       "1051      0.000000     79.416664    3.309028     0.000000     262.791931   \n",
       "1058      0.000000      0.233333    0.009722     0.000000       0.002269   \n",
       "\n",
       "      kurtosis_time  skewness_time  coeff_of_var_time    iqr_time  \\\n",
       "0         -0.920654       0.638463           0.960889  212.062506   \n",
       "1         -1.155962       0.531038           0.921882  247.795844   \n",
       "2         -1.028185       0.526891           0.897678  184.895827   \n",
       "3          0.110828       0.837585           0.928159  193.966663   \n",
       "4          0.219186       1.074547           1.029128  136.641668   \n",
       "...             ...            ...                ...         ...   \n",
       "1046      19.043478       4.587317           4.795832    0.000000   \n",
       "1049       8.400519       3.171385           3.366502    0.000000   \n",
       "1050      19.043478       4.587318           4.795832    0.000000   \n",
       "1051      19.043477       4.587317           4.795832    0.000000   \n",
       "1058      19.043473       4.587317           4.795831    0.000000   \n",
       "\n",
       "      trimmed_mean_time  ...      mean_freq    median_freq  variance_freq  \\\n",
       "0            120.149170  ...  145556.015625   94128.164062   1.245808e+10   \n",
       "1            142.218353  ...  225564.921875   66185.421875   7.144961e+10   \n",
       "2            115.246666  ...  337368.875000  233032.718750   9.313090e+10   \n",
       "3            114.235825  ...  293284.031250  243482.046875   2.841528e+10   \n",
       "4             88.289169  ...   75315.054688   50414.445312   2.197785e+09   \n",
       "...                 ...  ...            ...            ...            ...   \n",
       "1046           0.000000  ...       2.289002       2.780218   5.765709e-01   \n",
       "1049           0.000000  ...       0.236217       0.231677   5.128690e-03   \n",
       "1050           0.000000  ...       0.000408       0.000386   1.543398e-08   \n",
       "1051           0.000000  ...    8990.534180   10806.850586   8.876594e+06   \n",
       "1058           0.000000  ...       0.113264       0.136604   1.324863e-03   \n",
       "\n",
       "      kurtosis_freq  skewness_freq  coeff_of_var_freq       iqr_freq  \\\n",
       "0          0.335413       1.309549           0.766824   68011.867188   \n",
       "1         -0.185189       1.162469           1.185027  291117.929688   \n",
       "2         -0.446068       0.971081           0.904569  379323.562500   \n",
       "3         -1.273162       0.381854           0.574761  266578.562500   \n",
       "4          0.339903       1.245119           0.622459   29237.988281   \n",
       "...             ...            ...                ...            ...   \n",
       "1046       0.321710      -1.308182           0.331727       0.825352   \n",
       "1049       0.249235      -0.071112           0.303174       0.016871   \n",
       "1050      -0.032443       0.335318           0.304669       0.000028   \n",
       "1051       0.656679      -1.430759           0.331389    2489.757812   \n",
       "1058       0.377519      -1.322600           0.321361       0.038453   \n",
       "\n",
       "      trimmed_mean_freq  entropy_freq  spectral_flatness  \n",
       "0         131411.703125      3.339275           0.781018  \n",
       "1         191007.359375      2.800678           0.442222  \n",
       "2         306780.781250      3.145580           0.615705  \n",
       "3         286987.468750      3.457804           0.826515  \n",
       "4          69791.164062      3.455590           0.847506  \n",
       "...                 ...           ...                ...  \n",
       "1046           2.412409      3.599787           0.904552  \n",
       "1049           0.235667      3.629814           0.945994  \n",
       "1050           0.000403      3.632658           0.951204  \n",
       "1051        9508.233398      3.597398           0.898052  \n",
       "1058           0.119200      3.606872           0.912811  \n",
       "\n",
       "[991 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"full_24h\"].dropna(inplace=True)\n",
    "datasets[\"full_24h\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10ba1f",
   "metadata": {},
   "source": [
    "## Psykose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f315198",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:07:58.518557Z",
     "start_time": "2024-11-23T16:07:57.325757Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(dirpath=os.path.join(\"data_24h\", \"psykose\"))\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5686d4e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:08:05.844810Z",
     "start_time": "2024-11-23T16:07:58.519398Z"
    }
   },
   "outputs": [],
   "source": [
    "condition_parts_dfs = extract_features_for_dataframes(condition, freq=\"H\")\n",
    "control_parts_dfs = extract_features_for_dataframes(control, freq=\"H\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\"]:\n",
    "    condition_df = condition_parts_dfs[part]\n",
    "    control_df = control_parts_dfs[part]\n",
    "    \n",
    "    entire_df = pd.concat([condition_df, control_df], ignore_index=True)\n",
    "    \n",
    "    # Przypisujemy wynik do słownika datasets\n",
    "    datasets[part] = entire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc17091",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:08:05.858509Z",
     "start_time": "2024-11-23T16:08:05.845441Z"
    }
   },
   "outputs": [],
   "source": [
    "for part, df in datasets.items():\n",
    "    filename = f\"{PSYKOSE_PREFIX}_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e75053c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:08:05.863575Z",
     "start_time": "2024-11-23T16:08:05.859262Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.concatenate((np.ones(len(condition)), np.zeros(len(control))))\n",
    "y = pd.Series(y, dtype=int)\n",
    "\n",
    "filepath = os.path.join(PROCESSED_DATA_DIR, f\"psykose_y.csv\")\n",
    "y.to_csv(filepath, header=False, index=False)\n",
    "datasets[\"full_24h\"].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195102c",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff79d6",
   "metadata": {},
   "source": [
    "## Classifiers, parameters, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00c0242a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:08:05.867125Z",
     "start_time": "2024-11-23T16:08:05.864174Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LR\": LogisticRegression(\n",
    "        penalty=\"elasticnet\",\n",
    "        random_state=0,\n",
    "        solver=\"saga\",\n",
    "        max_iter=500\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        kernel=\"rbf\",\n",
    "        cache_size=512\n",
    "    ),\n",
    "    \"RF\": RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        criterion=\"entropy\"\n",
    "    ),\n",
    "    \"LGBM\": LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        verbosity=-1,\n",
    "        random_state=0\n",
    "    ),\n",
    "    \"XGB\": XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=0 \n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    \"LR\": {\n",
    "        \"C\": [0.001, 0.01, 0.1, 0.5, 1, 2, 5, 10, 25, 50, 100, 500, 1000],\n",
    "        \"class_weight\": [\"balanced\"],\n",
    "        \"l1_ratio\": [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,\n",
    "                     0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"class_weight\": [None, \"balanced\"]\n",
    "    },\n",
    "    \"RF\": {\n",
    "        \"class_weight\": [None, \"balanced\", \"balanced_subsample\"]\n",
    "    },\n",
    "    \"LGBM\": {\n",
    "        \"class_weight\": [None, \"balanced\"]\n",
    "    },\n",
    "    \"XGB\": {\n",
    "        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44383487",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "299853bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:08:05.869378Z",
     "start_time": "2024-11-23T16:08:05.867879Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = DEPRESJON_PREFIX  # DEPRESJON_PREFIX or PSYKOSE_PREFIX\n",
    "y_filename = \"depresjon_y.csv\" if dataset == DEPRESJON_PREFIX else \"psykose_y.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "518e18e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:08:05.875930Z",
     "start_time": "2024-11-23T16:08:05.869970Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming PROCESSED_DATA_DIR and y_filename are already defined\n",
    "datasets = {}\n",
    "\n",
    "# Load datasets\n",
    "for part in [\"full_24h\"]:\n",
    "    filename = f\"{dataset}_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    datasets[part] = pd.read_csv(filepath, header=0).values\n",
    "\n",
    "# Load y values\n",
    "y = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, y_filename), header=None, dtype=int)\n",
    "y = y.values.ravel()\n",
    "\n",
    "# Usuwanie wierszy, które zawierają NaN w danych\n",
    "for part in datasets:\n",
    "    # Indeksy wierszy, które zawierają NaN w dowolnej kolumnie\n",
    "    nan_indices = np.isnan(datasets[part]).any(axis=1)\n",
    "    \n",
    "    # Usuwamy te wiersze z datasets i y\n",
    "    datasets[part] = datasets[part][~nan_indices]\n",
    "    y = y[~nan_indices]\n",
    "\n",
    "# Sprawdzamy kształt danych po usunięciu NaN\n",
    "#print(datasets['full_24h'].shape)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb6e1ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:08:12.559816Z",
     "start_time": "2024-11-23T16:08:05.876623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki dla depresjon\n",
      "PART: full_24h\n",
      "  LR\n",
      "    accuracy: 0.5491 +- 0.0989\n",
      "    balanced_accuracy: 0.5089 +- 0.0121\n",
      "    f1: 0.2151 +- 0.2635\n",
      "    precision: 0.7540 +- 0.3013\n",
      "    recall: 0.3568 +- 0.4369\n",
      "    specificity: 0.6611 +- 0.4152\n",
      "    ROC_AUC: 0.5089 +- 0.0121\n",
      "    MCC: 0.0249 +- 0.0334\n",
      "\n",
      "  SVM\n",
      "    accuracy: 0.6256 +- 0.0096\n",
      "    balanced_accuracy: 0.4998 +- 0.0057\n",
      "    f1: 0.0204 +- 0.0185\n",
      "    precision: 0.7500 +- 0.3162\n",
      "    recall: 0.0108 +- 0.0101\n",
      "    specificity: 0.9888 +- 0.0187\n",
      "    ROC_AUC: 0.4998 +- 0.0057\n",
      "    MCC: 0.0136 +- 0.0472\n",
      "\n",
      "  RF\n",
      "    accuracy: 0.6095 +- 0.0288\n",
      "    balanced_accuracy: 0.5765 +- 0.0273\n",
      "    f1: 0.4591 +- 0.0404\n",
      "    precision: 0.4748 +- 0.0413\n",
      "    recall: 0.4483 +- 0.0575\n",
      "    specificity: 0.7046 +- 0.0522\n",
      "    ROC_AUC: 0.5765 +- 0.0273\n",
      "    MCC: 0.1558 +- 0.0565\n",
      "\n",
      "  LGBM\n",
      "    accuracy: 0.6347 +- 0.0244\n",
      "    balanced_accuracy: 0.5886 +- 0.0295\n",
      "    f1: 0.4526 +- 0.0497\n",
      "    precision: 0.5095 +- 0.0378\n",
      "    recall: 0.4100 +- 0.0654\n",
      "    specificity: 0.7672 +- 0.0336\n",
      "    ROC_AUC: 0.5886 +- 0.0295\n",
      "    MCC: 0.1872 +- 0.0584\n",
      "\n",
      "  XGB\n",
      "    accuracy: 0.6297 +- 0.0119\n",
      "    balanced_accuracy: 0.5882 +- 0.0167\n",
      "    f1: 0.4600 +- 0.0323\n",
      "    precision: 0.5012 +- 0.0177\n",
      "    recall: 0.4267 +- 0.0458\n",
      "    specificity: 0.7496 +- 0.0220\n",
      "    ROC_AUC: 0.5882 +- 0.0167\n",
      "    MCC: 0.1832 +- 0.0315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Wyniki dla depresjon\")\n",
    "for part in [\"full_24h\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    \n",
    "    X = datasets[part]\n",
    "\n",
    "    for clf_type in [\"LR\", \"SVM\", \"RF\", \"LGBM\", \"XGB\"]:\n",
    "        print(f\"  {clf_type}\")\n",
    "        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        \n",
    "        test_scores = []\n",
    "        for train_idx, test_idx in folds.split(X, y):\n",
    "            #print(train_idx, test_idx)\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            X_train, X_test = variance_thresholding(X_train, X_test, threshold=0.05)\n",
    "            X_train, X_test = standardize(X_train, X_test)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=classifiers[clf_type], \n",
    "                param_grid=param_grids[clf_type], \n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                refit=True,\n",
    "                #cv=LeaveOneOut()\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            clf = grid_search.best_estimator_\n",
    "            y_pred  = clf.predict(X_test)\n",
    "            metrics = calculate_metrics(y_test, y_pred)\n",
    "            #print(metrics)\n",
    "            test_scores.append(metrics)\n",
    "        \n",
    "        final_scores = calculate_metrics_statistics(test_scores)\n",
    "        \n",
    "        for metric, (mean, stddev) in final_scores.items():\n",
    "            print(f\"    {metric}: {mean:.4f} +- {stddev:.4f}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950979f23ade6a4e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Classification Psykose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc396b89f05818b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:08:12.562458Z",
     "start_time": "2024-11-23T16:08:12.560554Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = PSYKOSE_PREFIX  # DEPRESJON_PREFIX or PSYKOSE_PREFIX\n",
    "y_filename = \"depresjon_y.csv\" if dataset == DEPRESJON_PREFIX else \"psykose_y.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe30e87c47741458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:08:12.570016Z",
     "start_time": "2024-11-23T16:08:12.562931Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Assuming PROCESSED_DATA_DIR and y_filename are already defined\n",
    "datasets = {}\n",
    "\n",
    "# Load datasets\n",
    "for part in [\"full_24h\"]:\n",
    "    filename = f\"{dataset}_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    datasets[part] = pd.read_csv(filepath, header=0).values\n",
    "\n",
    "# Load y values\n",
    "y = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, y_filename), header=None, dtype=int)\n",
    "y = y.values.ravel()\n",
    "\n",
    "# Usuwanie wierszy, które zawierają NaN w danych\n",
    "for part in datasets:\n",
    "    # Indeksy wierszy, które zawierają NaN w dowolnej kolumnie\n",
    "    nan_indices = np.isnan(datasets[part]).any(axis=1)\n",
    "    \n",
    "    # Usuwamy te wiersze z datasets i y\n",
    "    datasets[part] = datasets[part][~nan_indices]\n",
    "    y = y[~nan_indices]\n",
    "\n",
    "# Sprawdzamy kształt danych po usunięciu NaN\n",
    "#print(datasets['full_24h'].shape)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a24c1f5fa0e4da8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T16:08:17.722809Z",
     "start_time": "2024-11-23T16:08:12.570556Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki dla psykose\n",
      "PART: full_24h\n",
      "  LR\n",
      "    accuracy: 0.5241 +- 0.0633\n",
      "    balanced_accuracy: 0.5466 +- 0.0323\n",
      "    f1: 0.4254 +- 0.2133\n",
      "    precision: 0.5218 +- 0.2397\n",
      "    recall: 0.6286 +- 0.3154\n",
      "    specificity: 0.4645 +- 0.2728\n",
      "    ROC_AUC: 0.5466 +- 0.0323\n",
      "    MCC: 0.0984 +- 0.0663\n",
      "\n",
      "  SVM\n",
      "    accuracy: 0.6609 +- 0.0137\n",
      "    balanced_accuracy: 0.5481 +- 0.0160\n",
      "    f1: 0.2230 +- 0.0465\n",
      "    precision: 0.6674 +- 0.0985\n",
      "    recall: 0.1348 +- 0.0314\n",
      "    specificity: 0.9615 +- 0.0138\n",
      "    ROC_AUC: 0.5481 +- 0.0160\n",
      "    MCC: 0.1769 +- 0.0563\n",
      "\n",
      "  RF\n",
      "    accuracy: 0.6037 +- 0.0222\n",
      "    balanced_accuracy: 0.5725 +- 0.0280\n",
      "    f1: 0.4549 +- 0.0457\n",
      "    precision: 0.4544 +- 0.0345\n",
      "    recall: 0.4579 +- 0.0638\n",
      "    specificity: 0.6871 +- 0.0327\n",
      "    ROC_AUC: 0.5725 +- 0.0280\n",
      "    MCC: 0.1447 +- 0.0550\n",
      "\n",
      "  LGBM\n",
      "    accuracy: 0.6517 +- 0.0257\n",
      "    balanced_accuracy: 0.6029 +- 0.0315\n",
      "    f1: 0.4670 +- 0.0532\n",
      "    precision: 0.5275 +- 0.0476\n",
      "    recall: 0.4241 +- 0.0741\n",
      "    specificity: 0.7818 +- 0.0422\n",
      "    ROC_AUC: 0.6029 +- 0.0315\n",
      "    MCC: 0.2184 +- 0.0629\n",
      "\n",
      "  XGB\n",
      "    accuracy: 0.6394 +- 0.0261\n",
      "    balanced_accuracy: 0.5908 +- 0.0250\n",
      "    f1: 0.4535 +- 0.0377\n",
      "    precision: 0.5080 +- 0.0435\n",
      "    recall: 0.4128 +- 0.0492\n",
      "    specificity: 0.7689 +- 0.0442\n",
      "    ROC_AUC: 0.5908 +- 0.0250\n",
      "    MCC: 0.1925 +- 0.0532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Wyniki dla psykose\")\n",
    "for part in [\"full_24h\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    \n",
    "    X = datasets[part]\n",
    "\n",
    "    for clf_type in [\"LR\", \"SVM\", \"RF\", \"LGBM\", \"XGB\"]:\n",
    "        print(f\"  {clf_type}\")\n",
    "        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        \n",
    "        test_scores = []\n",
    "        for train_idx, test_idx in folds.split(X, y):\n",
    "            #print(train_idx, test_idx)\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            X_train, X_test = variance_thresholding(X_train, X_test, threshold=0.05)\n",
    "            X_train, X_test = standardize(X_train, X_test)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=classifiers[clf_type], \n",
    "                param_grid=param_grids[clf_type], \n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                refit=True,\n",
    "                #cv=LeaveOneOut()\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            clf = grid_search.best_estimator_\n",
    "            y_pred  = clf.predict(X_test)\n",
    "            metrics = calculate_metrics(y_test, y_pred)\n",
    "            #print(metrics)\n",
    "            test_scores.append(metrics)\n",
    "        \n",
    "        final_scores = calculate_metrics_statistics(test_scores)\n",
    "        \n",
    "        for metric, (mean, stddev) in final_scores.items():\n",
    "            print(f\"    {metric}: {mean:.4f} +- {stddev:.4f}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1531cd3-5c7e-4fdd-9960-b18dee2e1d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
