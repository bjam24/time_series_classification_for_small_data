{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320837f7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "18e18bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:21.126968Z",
     "start_time": "2024-11-19T08:09:21.107117Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from utils import Dataset, variance_thresholding, standardize, mcc, calculate_metrics, calculate_metrics_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b84c8514",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:21.130105Z",
     "start_time": "2024-11-19T08:09:21.128133Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters for Welch's method for estimating power spectrum\n",
    "\n",
    "NPERSEG = 24                    # length of segment\n",
    "NOVERLAP = int(0.75 * NPERSEG)  # overlap of segments\n",
    "NFFT = NPERSEG                  # length of FFT\n",
    "WINDOW = \"hann\"                 # window function type\n",
    "\n",
    "# parameters for saving data\n",
    "PROCESSED_DATA_DIR = \"processed_data24h\"\n",
    "DEPRESJON_PREFIX = \"manual_depresjon24h\"\n",
    "PSYKOSE_PREFIX = \"manual_psykose24h\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef0d95",
   "metadata": {},
   "source": [
    "# Manual feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9515d10",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "657c3d7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:21.144496Z",
     "start_time": "2024-11-19T08:09:21.130992Z"
    }
   },
   "outputs": [],
   "source": [
    "def basic_data_cleaning(data: List[pd.DataFrame]) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Assumes DataFrames with \"timestamp\", \"date\" and \"activity\" columns.\n",
    "    \n",
    "    Performs cleaning operations:\n",
    "    - assure format YYYY-MM-DD HH:MM:SS for \"timestamp\"\n",
    "    - drop redundant \"date\" column\n",
    "    - assure float32 format for \"activity\"\n",
    "    \n",
    "    :param data: list of DataFrames\n",
    "    :returns: list of cleaned DataFrames\n",
    "    \"\"\"\n",
    "    data = [df.copy() for df in data]  # create copy to avoid side effects\n",
    "    \n",
    "    for df in data:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],\n",
    "                                         format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        df.drop(\"date\", axis=1, inplace=True)\n",
    "        df[\"activity\"] = df[\"activity\"].astype(np.float32)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_day_part(df: pd.DataFrame, part: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For given DataFrame with \"timestamp\" column returns only those rows that\n",
    "    correspond to the chosen part of day.\n",
    "    \n",
    "    Parts are \"day\" and \"night\", defined as:\n",
    "    - \"day\": [8:00, 21:00)\n",
    "    - \"night\": [21:00, 8:00)\n",
    "    \n",
    "    :param df: DataFrame to select rows from\n",
    "    :param part: part of day, either \"day\" or \"night\"\n",
    "    :returns: DataFrame, subset of rows of df\n",
    "    \"\"\"\n",
    "    if part == \"day\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 8) &\n",
    "                    (df[\"timestamp\"].dt.hour < 21)]\n",
    "    elif part == \"night\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 21) |\n",
    "                    (df[\"timestamp\"].dt.hour < 8)]\n",
    "    else:\n",
    "        raise ValueError(f'Part should be \"day\" or \"night\", got \"{part}\"')\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_missing_activity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Makes sure that \"timestamp\" column has minute resolution with no missing\n",
    "    values from start to end and replaces all NaNs in \"activity\" column with\n",
    "    mean average value.\n",
    "    \n",
    "    :param data: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    :returns: cleaned DataFrame\n",
    "    \"\"\"\n",
    "    df = df.copy()  # create copy to avoid side effects\n",
    "    \n",
    "    # resample to the basic frequency, i.e. minute; this will create NaNs for\n",
    "    # any rows that may be missing\n",
    "    df = df.resample(\"min\", on=\"timestamp\").mean()\n",
    "    \n",
    "    # recreate index and \"timestamp\" column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # fill any NaNs with mean activity value\n",
    "    df[\"activity\"] = df[\"activity\"].fillna(df[\"activity\"].mean())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def resample(df: pd.DataFrame, freq: str = \"H\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resamples time series DataFrame with given frequency, aggregating each\n",
    "    segment with a mean.\n",
    "\n",
    "    :param df: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    :param freq: resampling frequency passed to Pandas resample() function\n",
    "    :returns: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    \"\"\"\n",
    "    df = df.copy()  # create copy to avoid side effects\n",
    "    \n",
    "    # group with given frequency\n",
    "    df = df.resample(freq, on=\"timestamp\").mean()\n",
    "\n",
    "    # recreate \"timestamp\" column\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def proportion_of_zeros(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates proportion of zeros in given array, i.e. number of zeros divided\n",
    "    by length of array.\n",
    "    \n",
    "    :param x: 1D Numpy array\n",
    "    :returns: proportion of zeros\n",
    "    \"\"\"\n",
    "    # we may be dealing with floating numbers, we can't use direct comparison\n",
    "    zeros_count = np.sum(np.isclose(x, 0))\n",
    "    return zeros_count / len(x)\n",
    "\n",
    "\n",
    "def power_spectral_density(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates power spectral density (PSD) from \"activity\" column of a\n",
    "    DataFrame.\n",
    "    \n",
    "    :param df: DataFrame with \"activity\" column\n",
    "    :returns: 1D Numpy array with power spectral density\n",
    "    \"\"\"\n",
    "    psd = scipy.signal.welch(\n",
    "        x=df[\"activity\"].values,\n",
    "        fs=(1/24),\n",
    "        nperseg=11,\n",
    "        noverlap=10,\n",
    "        nfft=NFFT,\n",
    "        window=WINDOW,\n",
    "        scaling=\"density\"\n",
    "    )[1]\n",
    "    return psd\n",
    "\n",
    "\n",
    "def spectral_flatness(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculates spectral flatness of a signal, i.e. a geometric mean of the\n",
    "    power spectrum divided by the arithmetic mean of the power spectrum.\n",
    "    \n",
    "    If some frequency bins in the power spectrum are close to zero, they are\n",
    "    removed prior to calculation of spectral flatness to avoid calculation of\n",
    "    log(0).\n",
    "    \n",
    "    :param df: DataFrame with \"activity\" column\n",
    "    :returns: spectral flatness value\n",
    "    \"\"\"\n",
    "    power_spectrum = scipy.signal.welch(\n",
    "        df[\"activity\"].values,\n",
    "        fs=(1/24),\n",
    "        nperseg=11,\n",
    "        noverlap=10,\n",
    "        nfft=NFFT,\n",
    "        window=WINDOW,\n",
    "        scaling=\"spectrum\"\n",
    "    )[1]\n",
    "    \n",
    "    non_zeros_mask = ~np.isclose(power_spectrum, 0)\n",
    "    power_spectrum = power_spectrum[non_zeros_mask]\n",
    "    \n",
    "    return scipy.stats.gmean(power_spectrum) / power_spectrum.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c465a53",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16826d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:21.149515Z",
     "start_time": "2024-11-19T08:09:21.146087Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts features from activity signal in time domain.\n",
    "    \n",
    "    :param df_resampled: DataFrame with \"activity\" column\n",
    "    :returns: DataFrame with a single row representing features\n",
    "    \"\"\"\n",
    "    X = df[\"activity\"].values\n",
    "    \n",
    "    features = {\n",
    "        \"minimum\": np.min(X),\n",
    "        \"maximum\": np.max(X),\n",
    "        \"mean\": np.mean(X),\n",
    "        \"median\": np.median(X),\n",
    "        \"variance\": np.var(X, ddof=1),  # apply Bessel's correction\n",
    "        \"kurtosis\": sp.stats.kurtosis(X),\n",
    "        \"skewness\": sp.stats.skew(X),\n",
    "        \"coeff_of_var\": sp.stats.variation(X),\n",
    "        \"iqr\": sp.stats.iqr(X),\n",
    "        \"trimmed_mean\": sp.stats.trim_mean(X, proportiontocut=0.1),\n",
    "        \"entropy\": sp.stats.entropy(X, base=2),\n",
    "        \"proportion_of_zeros\": proportion_of_zeros(X)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9589aaf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:21.152633Z",
     "start_time": "2024-11-19T08:09:21.150245Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_frequency_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts features from activity signal in frequency domain, i.e. calculated\n",
    "    from its Power Spectral Density (PSD).\n",
    "    \n",
    "    :param df: DataFrame with \"activity\" column\n",
    "    :returns: DataFrame with a single row representing features\n",
    "    \"\"\"\n",
    "    X = power_spectral_density(df)\n",
    "    \n",
    "    features = {\n",
    "        \"minimum\": np.min(X),\n",
    "        \"maximum\": np.max(X),\n",
    "        \"mean\": np.mean(X),\n",
    "        \"median\": np.median(X),\n",
    "        \"variance\": np.var(X),\n",
    "        \"kurtosis\": sp.stats.kurtosis(X),\n",
    "        \"skewness\": sp.stats.skew(X),\n",
    "        \"coeff_of_var\": sp.stats.variation(X),\n",
    "        \"iqr\": sp.stats.iqr(X),\n",
    "        \"trimmed_mean\": sp.stats.trim_mean(X, proportiontocut=0.1),\n",
    "        \"entropy\": sp.stats.entropy(X, base=2),\n",
    "        \"spectral_flatness\": spectral_flatness(df)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e9867a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:21.156671Z",
     "start_time": "2024-11-19T08:09:21.153192Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_for_dataframes(dfs: List[pd.DataFrame], freq: str = \"H\") \\\n",
    "        -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculates time and frequency features for given DataFrames. Uses given\n",
    "    frequency for resampling.\n",
    "    \n",
    "    Calculates features separately for:\n",
    "    - full 24hs\n",
    "    - days: [8:00, 21:00)\n",
    "    - nights: [21:00, 8:00)\n",
    "    \n",
    "    :param dfs: list of DataFrames to extract features from; each one has to\n",
    "    have \"timestamp\" and \"activity\" columns\n",
    "    :param freq: resampling frequency\n",
    "    :returns: dictionary with keys \"full_24h\", \"day\" and \"night\", corresponding\n",
    "    to features from given parts of day\n",
    "    \"\"\"\n",
    "    full_dfs = basic_data_cleaning(dfs)\n",
    "    full_dfs = [fill_missing_activity(df) for df in full_dfs]\n",
    "    full_dfs = [resample(df, freq=freq) for df in full_dfs]\n",
    "    \n",
    "    night_dfs = [get_day_part(df, part=\"night\") for df in full_dfs]\n",
    "    day_dfs = [get_day_part(df, part=\"day\") for df in full_dfs]\n",
    "\n",
    "    datasets = {}\n",
    "    \n",
    "    for part, list_of_dfs in [(\"full_24h\", full_dfs), (\"night\", night_dfs),\n",
    "                              (\"day\", day_dfs)]:\n",
    "        features = []\n",
    "        for df in list_of_dfs:\n",
    "            time_features = extract_time_features(df)\n",
    "            freq_features = extract_frequency_features(df)\n",
    "\n",
    "            merged_features = pd.merge(\n",
    "                time_features,\n",
    "                freq_features,\n",
    "                left_index=True,\n",
    "                right_index=True,\n",
    "                suffixes=[\"_time\", \"_freq\"]\n",
    "            )\n",
    "            features.append(merged_features)\n",
    "\n",
    "        datasets[part] = pd.concat(features)\n",
    "        datasets[part].reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6d128",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Depresjon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "278e4de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:22.439858Z",
     "start_time": "2024-11-19T08:09:21.157115Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(dirpath=os.path.join(\"data_24h\", \"depresjon\"))\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0234b1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:22.448058Z",
     "start_time": "2024-11-19T08:09:22.440607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-06-20 10:30:00</td>\n",
       "      <td>2003-06-20</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-06-20 10:31:00</td>\n",
       "      <td>2003-06-20</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-06-20 10:32:00</td>\n",
       "      <td>2003-06-20</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-06-20 10:33:00</td>\n",
       "      <td>2003-06-20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-06-20 10:34:00</td>\n",
       "      <td>2003-06-20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2003-06-21 10:25:00</td>\n",
       "      <td>2003-06-21</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2003-06-21 10:26:00</td>\n",
       "      <td>2003-06-21</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2003-06-21 10:27:00</td>\n",
       "      <td>2003-06-21</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2003-06-21 10:28:00</td>\n",
       "      <td>2003-06-21</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2003-06-21 10:29:00</td>\n",
       "      <td>2003-06-21</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp        date  activity\n",
       "0     2003-06-20 10:30:00  2003-06-20        25\n",
       "1     2003-06-20 10:31:00  2003-06-20        36\n",
       "2     2003-06-20 10:32:00  2003-06-20        83\n",
       "3     2003-06-20 10:33:00  2003-06-20        19\n",
       "4     2003-06-20 10:34:00  2003-06-20         9\n",
       "...                   ...         ...       ...\n",
       "1435  2003-06-21 10:25:00  2003-06-21        12\n",
       "1436  2003-06-21 10:26:00  2003-06-21        32\n",
       "1437  2003-06-21 10:27:00  2003-06-21       265\n",
       "1438  2003-06-21 10:28:00  2003-06-21       155\n",
       "1439  2003-06-21 10:29:00  2003-06-21        47\n",
       "\n",
       "[1440 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eb28b3e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:29.572809Z",
     "start_time": "2024-11-19T08:09:22.448735Z"
    }
   },
   "outputs": [],
   "source": [
    "condition_parts_dfs = extract_features_for_dataframes(condition, freq=\"H\")\n",
    "control_parts_dfs = extract_features_for_dataframes(control, freq=\"H\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\"]:\n",
    "    condition_df = condition_parts_dfs[part]\n",
    "    control_df = control_parts_dfs[part]\n",
    "    \n",
    "    entire_df = pd.concat([condition_df, control_df], ignore_index=True)\n",
    "    \n",
    "    # Przypisujemy wynik do słownika datasets\n",
    "    datasets[part] = entire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cdbfbb10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:29.588519Z",
     "start_time": "2024-11-19T08:09:29.574857Z"
    }
   },
   "outputs": [],
   "source": [
    "for part, df in datasets.items():\n",
    "    filename = f\"{DEPRESJON_PREFIX}_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e9c20b2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:29.592298Z",
     "start_time": "2024-11-19T08:09:29.589059Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.concatenate((np.ones(len(condition)), np.zeros(len(control))))\n",
    "y = pd.Series(y, dtype=int)\n",
    "\n",
    "filepath = os.path.join(PROCESSED_DATA_DIR, f\"depresjon_y.csv\")\n",
    "y.to_csv(filepath, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9127c366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:29.601378Z",
     "start_time": "2024-11-19T08:09:29.592756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minimum_time</th>\n",
       "      <th>maximum_time</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>variance_time</th>\n",
       "      <th>kurtosis_time</th>\n",
       "      <th>skewness_time</th>\n",
       "      <th>coeff_of_var_time</th>\n",
       "      <th>iqr_time</th>\n",
       "      <th>trimmed_mean_time</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_freq</th>\n",
       "      <th>median_freq</th>\n",
       "      <th>variance_freq</th>\n",
       "      <th>kurtosis_freq</th>\n",
       "      <th>skewness_freq</th>\n",
       "      <th>coeff_of_var_freq</th>\n",
       "      <th>iqr_freq</th>\n",
       "      <th>trimmed_mean_freq</th>\n",
       "      <th>entropy_freq</th>\n",
       "      <th>spectral_flatness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.550000</td>\n",
       "      <td>691.683350</td>\n",
       "      <td>141.303329</td>\n",
       "      <td>94.250000</td>\n",
       "      <td>25246.462891</td>\n",
       "      <td>4.017333</td>\n",
       "      <td>1.999729</td>\n",
       "      <td>1.101751</td>\n",
       "      <td>140.183331</td>\n",
       "      <td>115.535706</td>\n",
       "      <td>...</td>\n",
       "      <td>7.056636e+05</td>\n",
       "      <td>4.037811e+05</td>\n",
       "      <td>3.285897e+11</td>\n",
       "      <td>-0.644289</td>\n",
       "      <td>0.955567</td>\n",
       "      <td>0.812324</td>\n",
       "      <td>7.698562e+05</td>\n",
       "      <td>6.469822e+05</td>\n",
       "      <td>3.269354</td>\n",
       "      <td>0.731094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>166.016663</td>\n",
       "      <td>77.510666</td>\n",
       "      <td>83.750000</td>\n",
       "      <td>2515.122803</td>\n",
       "      <td>-0.994866</td>\n",
       "      <td>0.062486</td>\n",
       "      <td>0.633948</td>\n",
       "      <td>68.666672</td>\n",
       "      <td>76.574600</td>\n",
       "      <td>...</td>\n",
       "      <td>7.105572e+04</td>\n",
       "      <td>7.937672e+04</td>\n",
       "      <td>6.719426e+08</td>\n",
       "      <td>-0.556905</td>\n",
       "      <td>-0.554086</td>\n",
       "      <td>0.364810</td>\n",
       "      <td>3.766367e+04</td>\n",
       "      <td>7.262927e+04</td>\n",
       "      <td>3.588991</td>\n",
       "      <td>0.903982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1083.199951</td>\n",
       "      <td>232.162231</td>\n",
       "      <td>206.983337</td>\n",
       "      <td>52457.531250</td>\n",
       "      <td>5.615858</td>\n",
       "      <td>1.980165</td>\n",
       "      <td>0.966603</td>\n",
       "      <td>298.649994</td>\n",
       "      <td>204.477234</td>\n",
       "      <td>...</td>\n",
       "      <td>1.801848e+06</td>\n",
       "      <td>1.463198e+06</td>\n",
       "      <td>9.874039e+11</td>\n",
       "      <td>-0.358756</td>\n",
       "      <td>0.865229</td>\n",
       "      <td>0.551480</td>\n",
       "      <td>8.479128e+05</td>\n",
       "      <td>1.731729e+06</td>\n",
       "      <td>3.493078</td>\n",
       "      <td>0.859510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.200000</td>\n",
       "      <td>1146.166626</td>\n",
       "      <td>383.709717</td>\n",
       "      <td>201.825012</td>\n",
       "      <td>186697.281250</td>\n",
       "      <td>-1.178148</td>\n",
       "      <td>0.701137</td>\n",
       "      <td>1.102363</td>\n",
       "      <td>825.245844</td>\n",
       "      <td>347.231659</td>\n",
       "      <td>...</td>\n",
       "      <td>3.672580e+06</td>\n",
       "      <td>1.105212e+06</td>\n",
       "      <td>1.906912e+13</td>\n",
       "      <td>-0.063627</td>\n",
       "      <td>1.227047</td>\n",
       "      <td>1.189033</td>\n",
       "      <td>3.419727e+06</td>\n",
       "      <td>3.069298e+06</td>\n",
       "      <td>2.823935</td>\n",
       "      <td>0.487504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>294.033325</td>\n",
       "      <td>56.151924</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>6219.544434</td>\n",
       "      <td>2.234426</td>\n",
       "      <td>1.756296</td>\n",
       "      <td>1.376101</td>\n",
       "      <td>69.760004</td>\n",
       "      <td>41.694355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.560999e+05</td>\n",
       "      <td>1.322794e+05</td>\n",
       "      <td>8.560280e+09</td>\n",
       "      <td>-1.190034</td>\n",
       "      <td>0.450418</td>\n",
       "      <td>0.592709</td>\n",
       "      <td>1.375921e+05</td>\n",
       "      <td>1.524360e+05</td>\n",
       "      <td>3.445226</td>\n",
       "      <td>0.819626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>2.316667</td>\n",
       "      <td>740.166687</td>\n",
       "      <td>312.192352</td>\n",
       "      <td>323.333313</td>\n",
       "      <td>69233.890625</td>\n",
       "      <td>-1.492479</td>\n",
       "      <td>0.096636</td>\n",
       "      <td>0.825079</td>\n",
       "      <td>499.283340</td>\n",
       "      <td>301.987488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.040252e+06</td>\n",
       "      <td>1.039700e+06</td>\n",
       "      <td>2.477260e+11</td>\n",
       "      <td>-0.869785</td>\n",
       "      <td>-0.521578</td>\n",
       "      <td>0.478462</td>\n",
       "      <td>5.855452e+05</td>\n",
       "      <td>1.062303e+06</td>\n",
       "      <td>3.495905</td>\n",
       "      <td>0.808007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1828.250000</td>\n",
       "      <td>353.719452</td>\n",
       "      <td>281.850006</td>\n",
       "      <td>195576.265625</td>\n",
       "      <td>3.833997</td>\n",
       "      <td>1.983241</td>\n",
       "      <td>1.223932</td>\n",
       "      <td>408.370827</td>\n",
       "      <td>266.735016</td>\n",
       "      <td>...</td>\n",
       "      <td>6.786808e+06</td>\n",
       "      <td>4.923788e+06</td>\n",
       "      <td>1.662164e+13</td>\n",
       "      <td>-0.627133</td>\n",
       "      <td>0.822168</td>\n",
       "      <td>0.600719</td>\n",
       "      <td>4.836770e+06</td>\n",
       "      <td>6.520742e+06</td>\n",
       "      <td>3.454776</td>\n",
       "      <td>0.835591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>7.550000</td>\n",
       "      <td>586.833313</td>\n",
       "      <td>272.634735</td>\n",
       "      <td>356.591675</td>\n",
       "      <td>47321.957031</td>\n",
       "      <td>-1.600275</td>\n",
       "      <td>-0.098908</td>\n",
       "      <td>0.781103</td>\n",
       "      <td>436.470829</td>\n",
       "      <td>268.144989</td>\n",
       "      <td>...</td>\n",
       "      <td>7.730123e+05</td>\n",
       "      <td>5.139775e+05</td>\n",
       "      <td>3.929674e+11</td>\n",
       "      <td>-1.430280</td>\n",
       "      <td>0.471400</td>\n",
       "      <td>0.810946</td>\n",
       "      <td>1.197435e+06</td>\n",
       "      <td>7.370223e+05</td>\n",
       "      <td>3.212892</td>\n",
       "      <td>0.658163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>2.016667</td>\n",
       "      <td>957.150024</td>\n",
       "      <td>393.095123</td>\n",
       "      <td>398.108337</td>\n",
       "      <td>98765.867188</td>\n",
       "      <td>-1.317137</td>\n",
       "      <td>0.079247</td>\n",
       "      <td>0.782644</td>\n",
       "      <td>633.341680</td>\n",
       "      <td>382.582489</td>\n",
       "      <td>...</td>\n",
       "      <td>1.737632e+06</td>\n",
       "      <td>1.778565e+06</td>\n",
       "      <td>1.157349e+12</td>\n",
       "      <td>-1.026521</td>\n",
       "      <td>0.173076</td>\n",
       "      <td>0.619119</td>\n",
       "      <td>1.876138e+06</td>\n",
       "      <td>1.700684e+06</td>\n",
       "      <td>3.386425</td>\n",
       "      <td>0.718106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>751.266663</td>\n",
       "      <td>382.361786</td>\n",
       "      <td>422.691650</td>\n",
       "      <td>80683.820312</td>\n",
       "      <td>-1.596979</td>\n",
       "      <td>-0.202751</td>\n",
       "      <td>0.727239</td>\n",
       "      <td>560.154184</td>\n",
       "      <td>385.222504</td>\n",
       "      <td>...</td>\n",
       "      <td>1.736764e+06</td>\n",
       "      <td>6.416590e+05</td>\n",
       "      <td>4.130266e+12</td>\n",
       "      <td>-0.215084</td>\n",
       "      <td>1.149394</td>\n",
       "      <td>1.170168</td>\n",
       "      <td>1.911201e+06</td>\n",
       "      <td>1.475566e+06</td>\n",
       "      <td>2.814729</td>\n",
       "      <td>0.438737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      minimum_time  maximum_time   mean_time  median_time  variance_time  \\\n",
       "0         1.550000    691.683350  141.303329    94.250000   25246.462891   \n",
       "1         0.000000    166.016663   77.510666    83.750000    2515.122803   \n",
       "2         0.000000   1083.199951  232.162231   206.983337   52457.531250   \n",
       "3         8.200000   1146.166626  383.709717   201.825012  186697.281250   \n",
       "4         0.616667    294.033325   56.151924    25.100000    6219.544434   \n",
       "...            ...           ...         ...          ...            ...   \n",
       "1058      2.316667    740.166687  312.192352   323.333313   69233.890625   \n",
       "1059      0.750000   1828.250000  353.719452   281.850006  195576.265625   \n",
       "1060      7.550000    586.833313  272.634735   356.591675   47321.957031   \n",
       "1062      2.016667    957.150024  393.095123   398.108337   98765.867188   \n",
       "1063      0.666667    751.266663  382.361786   422.691650   80683.820312   \n",
       "\n",
       "      kurtosis_time  skewness_time  coeff_of_var_time    iqr_time  \\\n",
       "0          4.017333       1.999729           1.101751  140.183331   \n",
       "1         -0.994866       0.062486           0.633948   68.666672   \n",
       "2          5.615858       1.980165           0.966603  298.649994   \n",
       "3         -1.178148       0.701137           1.102363  825.245844   \n",
       "4          2.234426       1.756296           1.376101   69.760004   \n",
       "...             ...            ...                ...         ...   \n",
       "1058      -1.492479       0.096636           0.825079  499.283340   \n",
       "1059       3.833997       1.983241           1.223932  408.370827   \n",
       "1060      -1.600275      -0.098908           0.781103  436.470829   \n",
       "1062      -1.317137       0.079247           0.782644  633.341680   \n",
       "1063      -1.596979      -0.202751           0.727239  560.154184   \n",
       "\n",
       "      trimmed_mean_time  ...     mean_freq   median_freq  variance_freq  \\\n",
       "0            115.535706  ...  7.056636e+05  4.037811e+05   3.285897e+11   \n",
       "1             76.574600  ...  7.105572e+04  7.937672e+04   6.719426e+08   \n",
       "2            204.477234  ...  1.801848e+06  1.463198e+06   9.874039e+11   \n",
       "3            347.231659  ...  3.672580e+06  1.105212e+06   1.906912e+13   \n",
       "4             41.694355  ...  1.560999e+05  1.322794e+05   8.560280e+09   \n",
       "...                 ...  ...           ...           ...            ...   \n",
       "1058         301.987488  ...  1.040252e+06  1.039700e+06   2.477260e+11   \n",
       "1059         266.735016  ...  6.786808e+06  4.923788e+06   1.662164e+13   \n",
       "1060         268.144989  ...  7.730123e+05  5.139775e+05   3.929674e+11   \n",
       "1062         382.582489  ...  1.737632e+06  1.778565e+06   1.157349e+12   \n",
       "1063         385.222504  ...  1.736764e+06  6.416590e+05   4.130266e+12   \n",
       "\n",
       "      kurtosis_freq  skewness_freq  coeff_of_var_freq      iqr_freq  \\\n",
       "0         -0.644289       0.955567           0.812324  7.698562e+05   \n",
       "1         -0.556905      -0.554086           0.364810  3.766367e+04   \n",
       "2         -0.358756       0.865229           0.551480  8.479128e+05   \n",
       "3         -0.063627       1.227047           1.189033  3.419727e+06   \n",
       "4         -1.190034       0.450418           0.592709  1.375921e+05   \n",
       "...             ...            ...                ...           ...   \n",
       "1058      -0.869785      -0.521578           0.478462  5.855452e+05   \n",
       "1059      -0.627133       0.822168           0.600719  4.836770e+06   \n",
       "1060      -1.430280       0.471400           0.810946  1.197435e+06   \n",
       "1062      -1.026521       0.173076           0.619119  1.876138e+06   \n",
       "1063      -0.215084       1.149394           1.170168  1.911201e+06   \n",
       "\n",
       "      trimmed_mean_freq  entropy_freq  spectral_flatness  \n",
       "0          6.469822e+05      3.269354           0.731094  \n",
       "1          7.262927e+04      3.588991           0.903982  \n",
       "2          1.731729e+06      3.493078           0.859510  \n",
       "3          3.069298e+06      2.823935           0.487504  \n",
       "4          1.524360e+05      3.445226           0.819626  \n",
       "...                 ...           ...                ...  \n",
       "1058       1.062303e+06      3.495905           0.808007  \n",
       "1059       6.520742e+06      3.454776           0.835591  \n",
       "1060       7.370223e+05      3.212892           0.658163  \n",
       "1062       1.700684e+06      3.386425           0.718106  \n",
       "1063       1.475566e+06      2.814729           0.438737  \n",
       "\n",
       "[991 rows x 24 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"full_24h\"].dropna(inplace=True)\n",
    "datasets[\"full_24h\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10ba1f",
   "metadata": {},
   "source": [
    "## Psykose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4f315198",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:30.788698Z",
     "start_time": "2024-11-19T08:09:29.601957Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(dirpath=os.path.join(\"data_24h\", \"psykose\"))\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5686d4e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:37.531610Z",
     "start_time": "2024-11-19T08:09:30.789302Z"
    }
   },
   "outputs": [],
   "source": [
    "condition_parts_dfs = extract_features_for_dataframes(condition, freq=\"H\")\n",
    "control_parts_dfs = extract_features_for_dataframes(control, freq=\"H\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\"]:\n",
    "    condition_df = condition_parts_dfs[part]\n",
    "    control_df = control_parts_dfs[part]\n",
    "    \n",
    "    entire_df = pd.concat([condition_df, control_df], ignore_index=True)\n",
    "    \n",
    "    # Przypisujemy wynik do słownika datasets\n",
    "    datasets[part] = entire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3cc17091",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:37.543874Z",
     "start_time": "2024-11-19T08:09:37.532340Z"
    }
   },
   "outputs": [],
   "source": [
    "for part, df in datasets.items():\n",
    "    filename = f\"{PSYKOSE_PREFIX}_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e75053c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:37.548057Z",
     "start_time": "2024-11-19T08:09:37.544418Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.concatenate((np.ones(len(condition)), np.zeros(len(control))))\n",
    "y = pd.Series(y, dtype=int)\n",
    "\n",
    "filepath = os.path.join(PROCESSED_DATA_DIR, f\"psykose_y.csv\")\n",
    "y.to_csv(filepath, header=False, index=False)\n",
    "datasets[\"full_24h\"].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195102c",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff79d6",
   "metadata": {},
   "source": [
    "## Classifiers, parameters, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "00c0242a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:37.551221Z",
     "start_time": "2024-11-19T08:09:37.548805Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LR\": LogisticRegression(\n",
    "        penalty=\"elasticnet\",\n",
    "        random_state=0,\n",
    "        solver=\"saga\",\n",
    "        max_iter=500\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        kernel=\"rbf\",\n",
    "        cache_size=512\n",
    "    ),\n",
    "    \"RF\": RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        criterion=\"entropy\"\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    \"LR\": {\n",
    "        \"C\": [0.5, 1, 2, 5],\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"l1_ratio\": [ 0.4, 0.45, 0.5,0.55, 0.6, 0.65]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"class_weight\": [None, \"balanced\"]\n",
    "    },\n",
    "    \"RF\": {\n",
    "        \"class_weight\": [None, \"balanced\", \"balanced_subsample\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44383487",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "299853bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:37.553297Z",
     "start_time": "2024-11-19T08:09:37.551816Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = DEPRESJON_PREFIX  # DEPRESJON_PREFIX or PSYKOSE_PREFIX\n",
    "y_filename = \"depresjon_y.csv\" if dataset == DEPRESJON_PREFIX else \"psykose_y.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "518e18e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:09:37.559550Z",
     "start_time": "2024-11-19T08:09:37.553940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(991, 24)\n",
      "(991,)\n"
     ]
    }
   ],
   "source": [
    "# Assuming PROCESSED_DATA_DIR and y_filename are already defined\n",
    "datasets = {}\n",
    "\n",
    "# Load datasets\n",
    "for part in [\"full_24h\"]:\n",
    "    filename = f\"{dataset}_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    datasets[part] = pd.read_csv(filepath, header=0).values\n",
    "\n",
    "# Load y values\n",
    "y = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, y_filename), header=None, dtype=int)\n",
    "y = y.values.ravel()\n",
    "\n",
    "# Usuwanie wierszy, które zawierają NaN w danych\n",
    "for part in datasets:\n",
    "    # Indeksy wierszy, które zawierają NaN w dowolnej kolumnie\n",
    "    nan_indices = np.isnan(datasets[part]).any(axis=1)\n",
    "    \n",
    "    # Usuwamy te wiersze z datasets i y\n",
    "    datasets[part] = datasets[part][~nan_indices]\n",
    "    y = y[~nan_indices]\n",
    "\n",
    "# Sprawdzamy kształt danych po usunięciu NaN\n",
    "print(datasets['full_24h'].shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eb6e1ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:55.096162Z",
     "start_time": "2024-11-19T08:09:37.560104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART: full_24h\n",
      "  LR\n",
      "{'accuracy': 0.628140703517588, 'balanced_accuracy': 0.5, 'f1': 0.0, 'precision': 1.0, 'recall': 0.0, 'specificity': 1.0, 'ROC_AUC': 0.5, 'MCC': 0.0}\n",
      "{'accuracy': 0.6262626262626263, 'balanced_accuracy': 0.5, 'f1': 0.0, 'precision': 1.0, 'recall': 0.0, 'specificity': 1.0, 'ROC_AUC': 0.5, 'MCC': 0.0}\n",
      "{'accuracy': 0.6262626262626263, 'balanced_accuracy': 0.5, 'f1': 0.0, 'precision': 1.0, 'recall': 0.0, 'specificity': 1.0, 'ROC_AUC': 0.5, 'MCC': 0.0}\n",
      "{'accuracy': 0.6313131313131313, 'balanced_accuracy': 0.5, 'f1': 0.0, 'precision': 1.0, 'recall': 0.0, 'specificity': 1.0, 'ROC_AUC': 0.5, 'MCC': 0.0}\n",
      "{'accuracy': 0.6313131313131313, 'balanced_accuracy': 0.5, 'f1': 0.0, 'precision': 1.0, 'recall': 0.0, 'specificity': 1.0, 'ROC_AUC': 0.5, 'MCC': 0.0}\n",
      "    accuracy: 0.6287 +- 0.0023\n",
      "    balanced_accuracy: 0.5000 +- 0.0000\n",
      "    f1: 0.0000 +- 0.0000\n",
      "    precision: 1.0000 +- 0.0000\n",
      "    recall: 0.0000 +- 0.0000\n",
      "    specificity: 1.0000 +- 0.0000\n",
      "    ROC_AUC: 0.5000 +- 0.0000\n",
      "    MCC: 0.0000 +- 0.0000\n",
      "\n",
      "  SVM\n",
      "{'accuracy': 0.628140703517588, 'balanced_accuracy': 0.5, 'f1': 0.0, 'precision': 1.0, 'recall': 0.0, 'specificity': 1.0, 'ROC_AUC': 0.5, 'MCC': 0.0}\n",
      "{'accuracy': 0.6161616161616161, 'balanced_accuracy': 0.49465998256320837, 'f1': 0.025641025641025644, 'precision': 0.25, 'recall': 0.013513513513513514, 'specificity': 0.9758064516129032, 'ROC_AUC': 0.4946599825632084, 'MCC': -0.03672556726227698}\n",
      "{'accuracy': 0.6212121212121212, 'balanced_accuracy': 0.4986922406277245, 'f1': 0.025974025974025972, 'precision': 0.3333333333333333, 'recall': 0.013513513513513514, 'specificity': 0.9838709677419355, 'ROC_AUC': 0.49869224062772455, 'MCC': -0.010358732215371954}\n",
      "{'accuracy': 0.5707070707070707, 'balanced_accuracy': 0.5460273972602739, 'f1': 0.4370860927152318, 'precision': 0.4230769230769231, 'recall': 0.4520547945205479, 'specificity': 0.64, 'ROC_AUC': 0.5460273972602739, 'MCC': 0.09089184624256737}\n",
      "{'accuracy': 0.6313131313131313, 'balanced_accuracy': 0.5, 'f1': 0.0, 'precision': 1.0, 'recall': 0.0, 'specificity': 1.0, 'ROC_AUC': 0.5, 'MCC': 0.0}\n",
      "    accuracy: 0.6135 +- 0.0220\n",
      "    balanced_accuracy: 0.5079 +- 0.0192\n",
      "    f1: 0.0977 +- 0.1701\n",
      "    precision: 0.6013 +- 0.3301\n",
      "    recall: 0.0958 +- 0.1782\n",
      "    specificity: 0.9199 +- 0.1403\n",
      "    ROC_AUC: 0.5079 +- 0.0192\n",
      "    MCC: 0.0088 +- 0.0432\n",
      "\n",
      "  RF\n",
      "{'accuracy': 0.5879396984924623, 'balanced_accuracy': 0.5562162162162163, 'f1': 0.4383561643835616, 'precision': 0.4444444444444444, 'recall': 0.43243243243243246, 'specificity': 0.68, 'ROC_AUC': 0.5562162162162162, 'MCC': 0.11308222999369373}\n",
      "{'accuracy': 0.6464646464646465, 'balanced_accuracy': 0.6251089799476897, 'f1': 0.5333333333333333, 'precision': 0.5263157894736842, 'recall': 0.5405405405405406, 'specificity': 0.7096774193548387, 'ROC_AUC': 0.6251089799476897, 'MCC': 0.24891924199150844}\n",
      "{'accuracy': 0.5858585858585859, 'balanced_accuracy': 0.5358544027898866, 'f1': 0.3787878787878788, 'precision': 0.43103448275862066, 'recall': 0.33783783783783783, 'specificity': 0.7338709677419355, 'ROC_AUC': 0.5358544027898866, 'MCC': 0.07622916744524647}\n",
      "{'accuracy': 0.6161616161616161, 'balanced_accuracy': 0.5877260273972602, 'f1': 0.4794520547945205, 'precision': 0.4794520547945205, 'recall': 0.4794520547945205, 'specificity': 0.696, 'ROC_AUC': 0.5877260273972602, 'MCC': 0.17545205479452056}\n",
      "{'accuracy': 0.5959595959595959, 'balanced_accuracy': 0.5688767123287671, 'f1': 0.4594594594594595, 'precision': 0.4533333333333333, 'recall': 0.4657534246575342, 'specificity': 0.672, 'ROC_AUC': 0.5688767123287671, 'MCC': 0.13700475919750546}\n",
      "    accuracy: 0.6065 +- 0.0227\n",
      "    balanced_accuracy: 0.5748 +- 0.0303\n",
      "    f1: 0.4579 +- 0.0506\n",
      "    precision: 0.4669 +- 0.0337\n",
      "    recall: 0.4512 +- 0.0666\n",
      "    specificity: 0.6983 +- 0.0220\n",
      "    ROC_AUC: 0.5748 +- 0.0303\n",
      "    MCC: 0.1501 +- 0.0590\n"
     ]
    }
   ],
   "source": [
    "for part in [\"full_24h\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    \n",
    "    X = datasets[part]\n",
    "\n",
    "    for clf_type in [\"LR\", \"SVM\", \"RF\"]:\n",
    "        print(f\"  {clf_type}\")\n",
    "        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        \n",
    "        test_scores = []\n",
    "        for train_idx, test_idx in folds.split(X, y):\n",
    "            #print(train_idx, test_idx)\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            X_train, X_test = variance_thresholding(X_train, X_test, threshold=0.05)\n",
    "            X_train, X_test = standardize(X_train, X_test)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=classifiers[clf_type], \n",
    "                param_grid=param_grids[clf_type], \n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                refit=True,\n",
    "                cv=LeaveOneOut()\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            clf = grid_search.best_estimator_\n",
    "            \n",
    "            metrics = calculate_metrics(clf, X_test, y_test)\n",
    "            print(metrics)\n",
    "            test_scores.append(metrics)\n",
    "        \n",
    "        final_scores = calculate_metrics_statistics(test_scores)\n",
    "        \n",
    "        for metric, (mean, stddev) in final_scores.items():\n",
    "            print(f\"    {metric}: {mean:.4f} +- {stddev:.4f}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fc396b89f05818b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:55.098691Z",
     "start_time": "2024-11-19T08:16:55.097203Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
